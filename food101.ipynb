{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- train with train, val and test set (need to write a loop)\n",
    "- instead of sampling from data, split data evenly into 7 chunks and train through them\n",
    "- install tf 1.11 or 1.12, move to tf.keras and try other models\n",
    "- try ensemble (stacking and bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n",
      "['train_images', 'train.csv', 'test_images', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.data import imread\n",
    "import os,cv2\n",
    "print(os.listdir(\"data\"))\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train.head(5)\n",
    "\n",
    "y = train.food_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/11363 [00:00<02:48, 67.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11363/11363 [02:54<00:00, 65.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beet_salad' 'bibimbap' 'nachos' ... 'lasagna' 'prime_rib' 'filet_mignon']\n"
     ]
    }
   ],
   "source": [
    "seed = 220\n",
    "x_train, x_val, y_train, y_val = train_test_split(train.index, \n",
    "                                                  train.food_type, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=seed, \n",
    "                                                  stratify=train.food_type)\n",
    "\n",
    "X = train.iloc[x_val]\n",
    "\n",
    "from tqdm import tqdm\n",
    "train_dir = 'data/train_images'\n",
    "\n",
    "images = []\n",
    "train_types = []\n",
    "\n",
    "train_files = [train_dir + '/' + filename for filename in X.filename]\n",
    "print(len(train_files))\n",
    "\n",
    "\n",
    "for filename in tqdm(train_files):\n",
    "    if filename.endswith('jpg'):\n",
    "        try:\n",
    "            images.append(cv2.resize(cv2.imread(filename), (299,299), interpolation=cv2.INTER_CUBIC))\n",
    "            train_types.append(train[train_dir + '/' + train['filename'] == filename]['food_type'])\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "train_types_arr = np.concatenate(train_types)\n",
    "print(train_types_arr)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(images, \n",
    "                                                  train_types_arr, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=1, \n",
    "                                                  stratify=train_types_arr)\n",
    "\n",
    "\n",
    "y_train_dummy = np.array(pd.get_dummies(y_train)) # turn to one-hot\n",
    "y_val_dummy = np.array(pd.get_dummies(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    #rescale=1./255,\n",
    "    zoom_range=[.8, 1],\n",
    "    fill_mode='reflect') # originally 'nearest'\n",
    "datagen.fit(x_train)\n",
    "generator = datagen.flow(x_train, y_train_dummy, batch_size=batch_size)\n",
    "val_generator = datagen.flow(x_val, y_val_dummy, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def build_model(model_name=\"inception_v3\"):\n",
    "    K.clear_session()\n",
    "    if model_name == \"inception_v3\":\n",
    "        from keras.applications.inception_v3 import InceptionV3     \n",
    "        base_model = InceptionV3(weights='imagenet', \n",
    "                                 include_top=False, \n",
    "                                 input_tensor=Input(shape=(299, 299, 3)))\n",
    "    if model_name == \"xception_v1\":\n",
    "        from keras.applications.xception import Xception\n",
    "        base_model = Xception(weights='imagenet', \n",
    "                              include_top=False, \n",
    "                              input_tensor=Input(shape=(299, 299, 3)))\n",
    "    if model_name == \"mobile_v2\":\n",
    "        from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "        base_model = MobileNetV2(weights='imagenet', \n",
    "                                 include_top=False, \n",
    "                                 input_tensor=Input(shape=(299, 299, 3)))\n",
    "            \n",
    "    if model_name == \"dense_121\":\n",
    "        from keras.applications.densenet import DenseNet121\n",
    "        base_model = DenseNet121(weights='imagenet', \n",
    "                                 include_top=False, \n",
    "                                 input_tensor=Input(shape=(299, 299, 3)))\n",
    "    if model_name == \"nas_mobile\":\n",
    "        from keras.applications.nasnet import NASNetMobile\n",
    "        base_model = NASNetMobile(weights='imagenet', \n",
    "                                 include_top=False, \n",
    "                                 input_tensor=Input(shape=(299, 299, 3)))\n",
    "    if model_name == \"resnet50\":\n",
    "        from keras.applications.resnet50 import ResNet50\n",
    "        base_model =ResNet50(weights='imagenet', \n",
    "                             include_top=False, \n",
    "                             input_tensor=Input(shape=(299, 299, 3)))\n",
    "    if model_name == \"inception_res\":\n",
    "        from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "        base_model = InceptionResNetV2(weights='imagenet', \n",
    "                             include_top=False, \n",
    "                             input_tensor=Input(shape=(299, 299, 3)))\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = AveragePooling2D(pool_size=(8, 8))(x) # originally 5,5\n",
    "    x = Dropout(.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(101, \n",
    "                        init='glorot_uniform', \n",
    "                        W_regularizer=l2(.0005), \n",
    "                        activation='softmax')(x)\n",
    "    return base_model, predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model_name, folder_name, restore_path=None):\n",
    "\n",
    "    base_model, predictions = build_model(model_name)\n",
    "\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer=SGD(lr=.01, momentum=.9), loss='categorical_crossentropy', metrics=['accuracy','top_k_categorical_accuracy'])\n",
    "\n",
    "    if restore_path is not None:\n",
    "        model.load_weights(restore_path)\n",
    "        \n",
    "    if os.path.isdir(\"training_logs/\" + folder_name):\n",
    "        os.rmdir(\"training_logs/\" + folder_name)\n",
    "    print(\"training_logs/\" + folder_name)\n",
    "    os.mkdir(\"training_logs/\" + folder_name)\n",
    "    os.mkdir(\"training_logs/\" + folder_name + \"/logs\")\n",
    "    os.mkdir(\"training_logs/\" + folder_name + \"/models\")\n",
    "\n",
    "    from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau\n",
    "    def schedule(epoch):\n",
    "        if epoch < 12:\n",
    "            return .01\n",
    "        elif epoch < 20:\n",
    "            return .002\n",
    "        else:\n",
    "            return .0004\n",
    "    lr_scheduler = LearningRateScheduler(schedule)\n",
    "    checkpointer = ModelCheckpoint(filepath='training_logs/' + folder_name + '/models/model.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=True)\n",
    "    csv_logger = CSVLogger('training_logs/' + folder_name + '/logs/model.log')\n",
    "    # lr_scheduler = ReduceLROnPlateau(monitor='val_acc',\n",
    "    #                                          factor=0.2,\n",
    "    #                                          patience=4,\n",
    "    #                                          verbose=2,\n",
    "    #                                          mode='auto',\n",
    "    #                                          cooldown=0,\n",
    "    #                                          min_lr=0.0001)\n",
    "\n",
    "    food_model = model.fit_generator(generator,\n",
    "                                     validation_data=val_generator,\n",
    "                                     #nb_val_samples=x_val.shape[0],\n",
    "                                     validation_steps=x_val.shape[0]/batch_size,\n",
    "                                     samples_per_epoch=x_train.shape[0],\n",
    "                                     nb_epoch=15,\n",
    "                                     verbose=1,\n",
    "                                     callbacks=[lr_scheduler, csv_logger])\n",
    "    return food_model, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Logs And Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "\n",
    "def save_logs_and_model(fit_generator_model, model, folder_name):\n",
    "    res = cloudpickle.dumps(fit_generator_model.history)\n",
    "\n",
    "    with open(\"training_logs/\" + folder_name + \"/logs/history.pkl\", \"wb\") as f:\n",
    "        f.write(res)\n",
    "\n",
    "    model.save(\"training_logs/\" + folder_name + \"/models/model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:59: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(101, kernel_regularizer=<keras.reg..., activation=\"softmax\", kernel_initializer=\"glorot_uniform\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_logs/inception_v3_seed_220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:49: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., verbose=1, validation_data=<keras_pre..., steps_per_epoch=142, epochs=15, callbacks=[<keras.ca..., validation_steps=35)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "142/142 [==============================] - 127s 892ms/step - loss: 0.8203 - acc: 0.8148 - top_k_categorical_accuracy: 0.9478 - val_loss: 1.3530 - val_acc: 0.6987 - val_top_k_categorical_accuracy: 0.9085\n",
      "Epoch 2/15\n",
      "142/142 [==============================] - 124s 871ms/step - loss: 0.4479 - acc: 0.8970 - top_k_categorical_accuracy: 0.9815 - val_loss: 0.8693 - val_acc: 0.8090 - val_top_k_categorical_accuracy: 0.9457\n",
      "Epoch 3/15\n",
      "142/142 [==============================] - 124s 876ms/step - loss: 0.3015 - acc: 0.9383 - top_k_categorical_accuracy: 0.9899 - val_loss: 0.8524 - val_acc: 0.7995 - val_top_k_categorical_accuracy: 0.9525\n",
      "Epoch 4/15\n",
      "142/142 [==============================] - 124s 873ms/step - loss: 0.2983 - acc: 0.9424 - top_k_categorical_accuracy: 0.9911 - val_loss: 0.8141 - val_acc: 0.8189 - val_top_k_categorical_accuracy: 0.9552\n",
      "Epoch 5/15\n",
      "142/142 [==============================] - 122s 861ms/step - loss: 0.2063 - acc: 0.9638 - top_k_categorical_accuracy: 0.9945 - val_loss: 0.7818 - val_acc: 0.8221 - val_top_k_categorical_accuracy: 0.9597\n",
      "Epoch 6/15\n",
      "142/142 [==============================] - 124s 870ms/step - loss: 0.2058 - acc: 0.9640 - top_k_categorical_accuracy: 0.9955 - val_loss: 0.9220 - val_acc: 0.7945 - val_top_k_categorical_accuracy: 0.9484\n",
      "Epoch 7/15\n",
      "142/142 [==============================] - 123s 864ms/step - loss: 0.1660 - acc: 0.9748 - top_k_categorical_accuracy: 0.9991 - val_loss: 0.9365 - val_acc: 0.7949 - val_top_k_categorical_accuracy: 0.9498\n",
      "Epoch 8/15\n",
      "142/142 [==============================] - 122s 859ms/step - loss: 0.1767 - acc: 0.9759 - top_k_categorical_accuracy: 0.9957 - val_loss: 0.7457 - val_acc: 0.8397 - val_top_k_categorical_accuracy: 0.9647\n",
      "Epoch 9/15\n",
      "142/142 [==============================] - 122s 862ms/step - loss: 0.1589 - acc: 0.9795 - top_k_categorical_accuracy: 0.9928 - val_loss: 0.7856 - val_acc: 0.8194 - val_top_k_categorical_accuracy: 0.9484\n",
      "Epoch 10/15\n",
      "142/142 [==============================] - 122s 856ms/step - loss: 0.1503 - acc: 0.9844 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.7728 - val_acc: 0.8212 - val_top_k_categorical_accuracy: 0.9597\n",
      "Epoch 11/15\n",
      "142/142 [==============================] - 121s 853ms/step - loss: 0.1466 - acc: 0.9834 - top_k_categorical_accuracy: 0.9962 - val_loss: 0.8016 - val_acc: 0.8176 - val_top_k_categorical_accuracy: 0.9556\n",
      "Epoch 12/15\n",
      "142/142 [==============================] - 120s 846ms/step - loss: 0.1437 - acc: 0.9827 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.6989 - val_acc: 0.8452 - val_top_k_categorical_accuracy: 0.9647\n",
      "Epoch 13/15\n",
      "142/142 [==============================] - 119s 836ms/step - loss: 0.1225 - acc: 0.9914 - top_k_categorical_accuracy: 0.9999 - val_loss: 0.6444 - val_acc: 0.8533 - val_top_k_categorical_accuracy: 0.9651\n",
      "Epoch 14/15\n",
      "142/142 [==============================] - 120s 843ms/step - loss: 0.1226 - acc: 0.9873 - top_k_categorical_accuracy: 0.9963 - val_loss: 0.6630 - val_acc: 0.8574 - val_top_k_categorical_accuracy: 0.9674\n",
      "Epoch 15/15\n",
      "142/142 [==============================] - 119s 838ms/step - loss: 0.0901 - acc: 0.9969 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6197 - val_acc: 0.8579 - val_top_k_categorical_accuracy: 0.9674\n"
     ]
    }
   ],
   "source": [
    "#model_names = [\"inception_v3\", \"xception_v1\", \"mobile_v2\", \"dense_121\", \"nas_mobile\", \"resnet50\", \"inception_res\"]\n",
    "# trained: resnet50, mobile_v2, nas_mobile, inception_res\n",
    "# can't be trained: xception_v1, dense_121\n",
    "model_names = [\"inception_v3\"]\n",
    "for model_name in model_names:\n",
    "    folder_name = model_name + \"_seed_\" + str(seed)\n",
    "    fit_generator_model, model = train(model_name, \n",
    "                                       folder_name, \n",
    "                                       restore_path=\"training_logs/inception_v3_seed_200/models/model.h5\")\n",
    "    save_logs_and_model(fit_generator_model, model, folder_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
